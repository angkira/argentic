llm:
  provider: gemma_jax

  # Model configuration
  gemma_model_size: "4B"  # or "2B"

  # Optional: specify checkpoint path (otherwise auto-downloads)
  # gemma_checkpoint_path: "/path/to/gemma-3-4b-it"

  # Generation parameters
  gemma_multi_turn: true
  max_output_tokens: 512
  temperature: 0.7
  top_p: 0.95
  top_k: 40

messaging:
  broker_address: localhost
  port: 1883

webrtc:
  video_buffer_size: 1
  resize_frames: [640, 480]
  enable_audio: true

visual_agent:
  auto_process_interval: 5.0
  enable_auto_processing: true
  visual_response_topic: "agent/visual/response"
  system_prompt: "You are a helpful visual AI assistant. Describe what you see clearly and concisely."

